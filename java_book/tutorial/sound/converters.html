<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
    

<html lang="en-US" xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Using Files and Format Converters (The Java&trade; Tutorials &gt;        
            Sound)
</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
     <meta name="description" content="" />
     <meta name="keywords" content="java programming, learn java, java sample code, " />
        
<style type="text/css">
    body {
        margin-left:10px;
        margin-right:10px;
        line-height: 1.5;
        FONT-FAMILY: Arial, Helvetica, sans-serif; 
        font-size: 0.8em;
    }
    
    a:link{text-decoration:none; color:#09569d;}
    a:visited{text-decoration:none; color: #3a87cf;}
    a:hover{text-decoration:underline; }
        
    code{
        font-family:Monaco,Courier,"Courier New";
    }
    
    .header-container {
        background-color: #fff;
        border-bottom: 1px solid #C1CFDA;
        -webkit-box-shadow: 0 2px 2px rgba(117, 163, 231, 0.1);
        box-shadow: 0 2px 2px rgba(117, 163, 231, 0.1);
    }
    
    .bookwrapper {
        width: auto;
        margin: auto;
    }
    
    .clearfix {
    }
    
    .clearfloat {
        clear: both;
        overflow: auto;
        height: 0px;
        font-size: 1px;
        line-height: 0px;
    }
    
    #brandProdName {
        width: auto;
        height: auto;
    }
    
    #logocover {
        display: block;
        background: transparent url(../images/oracle-java-logo.png) 0px 0px no-repeat;
        height: 50px;
        width: 229px;
        float: left;
    }
    
    #productName {
        font-size: 16px;
        position: relative;
        top: 19px;
        padding-left: 3px;
        color: #457798;
        white-space: nowrap;
        width: 340px;
    }


    .FigureCaption   { 
        font-family: sans-serif; 
        text-align: center;
    }
    
    #TopBar_bl {        
        width: 100%;
        height: 60px;
    }
    #TopBar_br {
        width: 100%;
        height: 60px;
    }
    #TopBar_tl {
        margin-left: -110px;
        margin-right: -100px;       
		align: left;
        height: 60px;
    }
    #TopBar_tr {
        width: 100%;
        height: 60px;
    }
    
    #TopBar {
        min-width:700px;
        padding:25px 100px 10px;
        margin-bottom:25px;
        clear:both;
        
        border-bottom:1px solid #d2dde5;
        border-radius: 3px;
    
        background:#efefef; /* Old browsers */
        /* IE9 SVG, needs conditional override of 'filter' to 'none' */
        background: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiA/Pgo8c3ZnIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgdmlld0JveD0iMCAwIDEgMSIgcHJlc2VydmVBc3BlY3RSYXRpbz0ibm9uZSI+CiAgPGxpbmVhckdyYWRpZW50IGlkPSJncmFkLXVjZ2ctZ2VuZXJhdGVkIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgeDE9IjAlIiB5MT0iMCUiIHgyPSIwJSIgeTI9IjEwMCUiPgogICAgPHN0b3Agb2Zmc2V0PSIwJSIgc3RvcC1jb2xvcj0iI2ZmZmZmZiIgc3RvcC1vcGFjaXR5PSIxIi8+CiAgICA8c3RvcCBvZmZzZXQ9IjEwMCUiIHN0b3AtY29sb3I9IiNlMmVmZjkiIHN0b3Atb3BhY2l0eT0iMSIvPgogIDwvbGluZWFyR3JhZGllbnQ+CiAgPHJlY3QgeD0iMCIgeT0iMCIgd2lkdGg9IjEiIGhlaWdodD0iMSIgZmlsbD0idXJsKCNncmFkLXVjZ2ctZ2VuZXJhdGVkKSIgLz4KPC9zdmc+);
        background: -moz-linear-gradient(top,  #ffffff 0%, #e2eff9 100%); /* FF3.6+ */
        background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,#ffffff), color-stop(100%,#e2eff9)); /* Chrome,Safari4+ */
        background: -webkit-linear-gradient(top,  #ffffff 0%,#e2eff9 100%); /* Chrome10+,Safari5.1+ */
        background: -o-linear-gradient(top,  #ffffff 0%,#e2eff9 100%); /* Opera 11.10+ */
        background: -ms-linear-gradient(top,  #ffffff 0%,#e2eff9 100%); /* IE10+ */
        background: linear-gradient(to bottom,  #ffffff 0%,#e2eff9 100%); /* W3C */
        filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#ffffff', endColorstr='#e2eff9',GradientType=0 ); /* IE6-8 */
        
    }
    
    #TopBar_left {
        line-height: 14px;
        position: absolute;
        padding-top: 30px;
        padding-right: 30px;
        padding-left: 30px;
        text-align: left;
        font: 13px/20px Arial, Helvetica, sans-serif;
        font-weight: bold;
        font-size: 20px;
        color: #333;
    }
    
    #TopBar_right {
        line-height: 12px;
        float: right;
        padding-top: 10px;
        padding-right: 30px;
        text-align: left;
    }
    

    @media print {
        #BreadCrumbs, #Download {
            display: none;
        }
    }
    
     
    @media print {
        #TopBar_right {
            display: none;
        }
    }
    #TopBar_right a {
        font-size: 10px;
        margin: 3px;
        padding: 0;
    }
 
    #BreadCrumbs {
        padding: 15px 5px 0.5em 0;
        font-family: sans-serif; 
        float: right;
    }
    
    #BreadCrumbs a {
        color:#09569d;
    }
    
    #BreadCrumbs a:visited, #BreadCrumbs a:link {
        text-decoration: none;
    }
    
    #BreadCrumbs a:hover, #BreadCrumbs a:active {
        text-decoration: underline;
    }
    
    #PageTitle {
        margin: 0 5px 0.5em 0;
        color: #F90000;
    }
    
    #PageContent{
        margin: 0 5px 0 20px;
    }
    
    .LeftBar_shown {
        width: 13em;
        float: left;
    }
    
    @media print {
        .LeftBar_shown {
            display: none;
        }
    }
    
    .LeftBar_hidden {
        display: none;
    }
    
    #Footer {
        padding-top: 10px;
        padding-left: 10px;
        margin-right: 10px;       
    }
    
    .footertext {
        font-size: 10px;
        font-family: sans-serif; 
        margin-top: 1px;
    }

    .NavBit  {
        padding: 15px 5px 0.5em 0;
        font-family: sans-serif; 
    }
    
    @media print {
        .NavBit {
            display: none;
        }
    }
    
    #TagNotes {
        text-align: right;        
    }
    
    @media print {
        #TagNotes a:visited, #TagNotes a:link {
            color: #35556B;
            text-decoration: none;
        }
    }
    
    #Contents a, .NavBit a, #TagNotes a {
        color:#09569d;
    }
    
    #TagNotes a:visited, #TagNotes a:link,
    #Contents a:visited, #Contents a:link,
    .NavBit a:visited, .NavBit a:link {
        text-decoration: none;
    }
    
    #TagNotes a:hover, #TagNotes a:active,   
    #Contents a:hover, #Contents a:active,   
    .NavBit a:hover, .NavBit a:active {  
        text-decoration: underline;
    }
    
    #Contents {
        float: left;
        font-family: sans-serif; 
    }
    @media print {
        #Contents {
            display: none;
        }
    }
    @media screen {
        div.PrintHeaders {
            display: none;
        }
    }
    .linkLESSON, .nolinkLESSON {
        margin-left: 0.5em;
        text-indent: -0.5em;
    }
    .linkAHEAD, .nolinkAHEAD, .linkQUESTIONS, .nolinkQUESTIONS   {
        margin-left: 1.5em; 
        text-indent: -0.5em
    }
    .linkBHEAD, .nolinkBHEAD   {
        margin-left: 2.5em;
        text-indent: -0.5em
    }
    .linkCHEAD, .nolinkCHEAD   {
        margin-left: 3.5em;
        text-indent: -0.5em
    }
    .nolinkLESSON, .nolinkAHEAD, .nolinkBHEAD, .nolinkCHEAD,
    .nolinkQUESTIONS {
        font-weight: bold;
        color: #333;
		
		
    }
    .MainFlow_indented {
        margin-right: 10px;
        margin-left: 15em;
        margin-bottom: 2em;

    }
    .MainFlow_wide {
	
        margin-right: 10px;
        margin-left: 10px;
        margin-bottom: 2em;

    }
    @media print {
        .MainFlow_indented, .MainFlow_wide {
            padding-top: 0;
            margin-top: 10px;
            margin-right: 10px;
            margin-left: 0;
        }
    }
    h1, h2, h3, h4, h5 {
        color: #333;
        
    }

    h1 {
        font-weight: bold;
        font-size: 20px;
    }

    h2 {
        font-weight: bold;
        font-size: 17px;
    }

    h3 {
        font-weight: bold;
        font-size: 14px;
    }

    h4 {
        font-size: 15px;
    }

    h5 {
        font-size: 12px;
    }


    #ToggleLeft {
        display: none;
    }
    
    .note {
        margin: 0 30px 0px 30px;
    }
    
    .codeblock {
        margin: 0 30px 0px 30px;
		font-size:12px;
		font-family:Monaco,Courier,"Courier New";
    }
    
    .tocli {
        list-style-type:none;
    }

    .betadraft {
        color: red;
    }
</style>
<script type="text/javascript">
/* <![CDATA[ */
    function leftBar() {
        var nameq = 'tutorial_showLeftBar='
        var cookies = document.cookie.split(';');
        for (var i = 0; i < cookies.length; i++) {
            var cookieString = cookies[i];
            while (cookieString.charAt(0) == ' ') {
                cookieString = cookieString.substring(1, cookieString.length);
            }
            if (cookieString.indexOf(nameq) == 0) {
                cookieValue =  cookieString.substring(nameq.length,
                        cookieString.length);
                return cookieValue == 'yes';
            }
        }
        return true;
    }

    function showLeft(b) {
        var contents = document.getElementById("LeftBar");
        var main = document.getElementById("MainFlow");
        var toggle = document.getElementById("ToggleLeft");
        if (b) {
            contents.className = "LeftBar_shown";
            main.className = "MainFlow_indented";
            toggle.innerHTML = "Hide TOC";
            document.cookie = 'tutorial_showLeftBar=yes; path=/';
        } else {
            contents.className = "LeftBar_hidden";
            main.className = "MainFlow_wide";
            toggle.innerHTML = "Show the TOC";
            document.cookie = 'tutorial_showLeftBar=no; path=/';
        }
    }

    function toggleLeft() {
        showLeft(document.getElementById("LeftBar").className ==
                "LeftBar_hidden");
        document.getElementById("ToggleLeft").blur();
    }

    function load() {
        showLeft(leftBar());
        document.getElementById("ToggleLeft").style.display="inline";
    }

    function showCode(displayCodePage, codePath) {
        var codePathEls = codePath.split("/");
        var currDocPathEls = location.href.split("/");
        //alert ("codePathEls = " + codePathEls + "\n" + "currDocPathEls = " + currDocPathEls);
        currDocPathEls.pop(); // remove file name at the end
        while (codePathEls.length > 0) {
            if (codePathEls[0] == "..") {
                codePathEls.shift();
                currDocPathEls.pop();
            } else {
                break;
            }
        }
        var fullCodePath = currDocPathEls.join("/") + "/" + codePathEls.join("/");
        //alert ("fullCodePath = " + fullCodePath );
        if (codePath.indexOf(".java") != -1 || codePath.indexOf(".jnlp") != -1) {
            window.location.href = displayCodePage + "?code=" + encodeURI(fullCodePath);
        } else {
            window.location.href = fullCodePath;
        }
    }
/* ]]> */    
</script>


    </head>
<body onload="load()">
    <noscript>
        A browser with JavaScript enabled is required for this page to operate properly.
    </noscript>
        <!-- header -->
    <div class="header-container">
        <div class="bookwrapper  clearfix">       
            <div id="brandProdName">
                <div id="logocover"></div>
                <div id="productName" >Documentation</div>
            </div> 
            <br class="clearfloat" />
        </div>
    </div>
    
    <div id="TopBar">
     <div id="TopBar_tr"> <div id="TopBar_tl"> <div id="TopBar_br"> <div id="TopBar_bl"> 
                        <div id="TopBar_left">
                            The Java&trade; Tutorials
                        </div>
                        <div id="TopBar_right"> 
                            <a target="_blank"
				href="http://www.oracle.com/technetwork/java/javase/downloads/java-se-7-tutorial-2012-02-28-1536013.html">Download Ebooks</a><br />
                            <a target="_blank"
                                href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Download JDK</a>
                            <br />
                            <a href="../search.html" target="_blank">Search Java Tutorials</a>
                            <br />           
                            <a href="javascript:toggleLeft()"
                                id="ToggleLeft">Hide TOC</a>
                        </div>
                    </div> </div> </div> </div> </div>


    <div id="LeftBar" class="LeftBar_shown">
        <div id="Contents">
            <div class="linkAHEAD"><a href="sampled-overview.html">Overview of the Sampled Package</a></div>
<div class="linkAHEAD"><a href="accessing.html">Accessing Audio System Resources</a></div>
<div class="linkAHEAD"><a href="playing.html">Playing Back Audio</a></div>
<div class="linkAHEAD"><a href="capturing.html">Capturing Audio</a></div>
<div class="linkAHEAD"><a href="controls.html">Processing Audio with Controls</a></div>
<div class="nolinkAHEAD">Using Files and Format Converters</div>
<div class="linkAHEAD"><a href="overview-MIDI.html">Overview of the MIDI Package</a></div>
<div class="linkAHEAD"><a href="accessing-MIDI.html">Accessing MIDI System Resources</a></div>
<div class="linkAHEAD"><a href="MIDI-messages.html">Transmitting and Receiving MIDI Messages</a></div>
<div class="linkAHEAD"><a href="MIDI-seq-intro.html">Introduction to Sequencers</a></div>
<div class="linkAHEAD"><a href="MIDI-seq-methods.html">Using Sequencer Methods</a></div>
<div class="linkAHEAD"><a href="MIDI-seq-adv.html">Using Advanced Sequencer Features</a></div>
<div class="linkAHEAD"><a href="MIDI-synth.html">Synthesizing Sound</a></div>
<div class="linkAHEAD"><a href="SPI-intro.html">Introduction to the Service Provider Interfaces</a></div>
<div class="linkAHEAD"><a href="SPI-providing-sampled.html">Providing Sampled-Audio Services</a></div>
<div class="linkAHEAD"><a href="SPI-providing-MIDI.html">Providing MIDI Services</a></div>
</div>
    </div>
    <div id="MainFlow" class="MainFlow_indented">
    <div class="PrintHeaders">
        <b>Trail:</b> Sound
    </div>
            <div id="BreadCrumbs">
                <a href="../index.html" target="_top">Home Page</a>
                &gt;
                <a href="./index.html" target="_top">Sound</a>
            </div>
            <div class="NavBit">
                <a target="_top" href="controls.html">&laquo;&nbsp;Previous</a>&nbsp;&bull;&nbsp;<a target="_top" href="./TOC.html">Trail</a>&nbsp;&bull;&nbsp;<a target="_top" href="overview-MIDI.html">Next&nbsp;&raquo;</a>
            </div>
            <div id="PageTitle"><h1>Using Files and Format Converters</h1></div>
            <div id="PageContent">

<p><a name="117603"></a> Most application programs that deal with sound need to read sound files or audio streams. This is common functionality, regardless of what the program may subsequently do with the data it reads (such as play, mix, or process it). Similarly, many programs need to write sound files (or streams). In some cases, the data that has been read (or that will be written) needs to be converted to a different format.</p>
<p><a name="117604"></a> As was briefly mentioned in 
<a class="TutorialLink" target="_top" href="accessing.html">Accessing Audio System Resources</a>, the Java Sound API provides application developers with various facilities for file input/output and format translations. Application programs can read, write, and translate between a variety of sound file formats and audio data formats.</p>
<p><a name="114517"></a> 
<a class="TutorialLink" target="_top" href="sampled-overview.html">Overview of the Sampled Package</a> introduced the main classes related to sound files and audio data formats. As a review:</p>
<ul>
<li><a name="114884"></a>A stream of audio data, as might be read from or written to a file, is represented by an <code>AudioInputStream</code> object. (<code>AudioInputStream</code> inherits from <code>java.io.InputStream</code>.)</li>
<li><a name="114885"></a>The format of this audio data is represented by an <code>AudioFormat</code> object.
<p><a name="117222"></a>This format specifies how the audio samples themselves are arranged, but not the structure of a file that they might be stored in. In other words, an <code>AudioFormat</code> describes &quot;raw&quot; audio data, such as the system might hand your program after capturing it from a microphone input or after parsing it from a sound file. An <code>AudioFormat</code> includes such information as the encoding, the byte order, the number of channels, the sampling rate, and the number of bits per sample.</p>
</li>
<li><a name="114521"></a>There are several well-known, standard formats for sound files, such as WAV, AIFF, or AU. The different types of sound file have different structures for storing audio data as well as for storing descriptive information about the audio data. A sound file format is represented in the Java Sound API by an <code>AudioFileFormat</code> object. The <code>AudioFileFormat</code> includes an <code>AudioFormat</code> object to describe the format of the audio data stored in the file, and also includes information about the file type and the length of the data in the file.</li>
<li><a name="114522"></a>The <code>AudioSystem</code> class provides methods for (1) storing a stream of audio data from an <code>AudioInputStream</code> into an audio file of a particular type (in other words, writing a file), (2) extracting a stream of audio bytes (an <code>AudioInputStream</code>) from an audio file (in other words, reading a file), and (3) converting audio data from one data format to another. This page, which is divided into three sections, explains these three kinds of activity.</li>
</ul>
<p><a name="114524"></a></p>
<div class="note"><hr /><strong>Note:</strong>&nbsp;<p>an implementation of the Java Sound API does not necessarily provide comprehensive facilities for reading, writing, and converting audio in different data and file formats. It might support only the most common data and file formats. However, service providers can develop and distribute conversion services that extend this set, as you&#39;ll later see in <a href="SPI-providing-sampled.html">Providing Sampled-Audio Services</a>. The <code>AudioSystem</code> class supplies methods that allow application programs to learn what conversions are available, as described later under <a href="#114640">Converting File and Data Formats</a>. <a name="114527"></a></p>
<hr /></div>
<h2>Reading Sound Files</h2>
<p><a name="114529"></a> The <code>AudioSystem</code> class provides two types of file-reading services:</p>
<ul>
<li><a name="114530"></a>Information about the format of the audio data stored in the sound file</li>
<li><a name="114531"></a>A stream of formatted audio data that can be read from the sound file</li>
</ul>
<p><a name="118569"></a> The first of these is given by three variants of the <code>getAudioFileFormat</code> method:</p>
<div class="codeblock"><pre>
    static AudioFileFormat getAudioFileFormat (java.io.File file)
    static AudioFileFormat getAudioFileFormat(java.io.InputStream stream)
    static AudioFileFormat getAudioFileFormat (java.net.URL url)
</pre></div>
<p>As mentioned above, the returned <code>AudioFileFormat</code> object tells you the file type, the length of the data in the file, encoding, the byte order, the number of channels, the sampling rate, and the number of bits per sample.</p>
<p><a name="114541"></a> The second type of file-reading functionality is given by these <code>AudioSystem</code> methods</p>
<div class="codeblock"><pre>
    static AudioInputStream getAudioInputStream (java.io.File file)
    static AudioInputStream getAudioInputStream (java.net.URL url)
    static AudioInputStream getAudioInputStream (java.io.InputStream stream)
</pre></div>
<p>These methods give you an object (an <code>AudioInputStream</code>) that lets you read the file&#39;s audio data, using one of the read methods of <code>AudioInputStream</code>. We&#39;ll see an example momentarily.</p>
<p><a name="114549"></a> Suppose you&#39;re writing a sound-editing application that allows the user to load sound data from a file, display a corresponding waveform or spectrogram, edit the sound, play back the edited data, and save the result in a new file. Or perhaps your program will read the data stored in a file, apply some kind of signal processing (such as an algorithm that slows the sound down without changing its pitch), and then play the processed audio. In either case, you need to get access to the data contained in the audio file. Assuming that your program provides some means for the user to select or specify an input sound file, reading that file&#39;s audio data involves three steps:</p>
<ol>
<li><a name="114551"></a>Get an <code>AudioInputStream</code> object from the file.</li>
<li><a name="114552"></a>Create a byte array in which you&#39;ll store successive chunks of data from the file.</li>
<li><a name="114553"></a>Repeatedly read bytes from the audio input stream into the array. On each iteration, do something useful with the bytes in the array (for example, you might play them, filter them, analyze them, display them, or write them to another file).</li>
</ol>
<p><a name="114555"></a> The following code snippet outlines these steps:</p>
<div class="codeblock"><pre>
int totalFramesRead = 0;
File fileIn = new File(somePathName);
// somePathName is a pre-existing string whose value was
// based on a user selection.
try {
  AudioInputStream audioInputStream = 
    AudioSystem.getAudioInputStream(fileIn);
  int bytesPerFrame = 
    audioInputStream.getFormat().getFrameSize();
    if (bytesPerFrame == AudioSystem.NOT_SPECIFIED) {
    // some audio formats may have unspecified frame size
    // in that case we may read any amount of bytes
    bytesPerFrame = 1;
  } 
  // Set an arbitrary buffer size of 1024 frames.
  int numBytes = 1024 * bytesPerFrame; 
  byte[] audioBytes = new byte[numBytes];
  try {
    int numBytesRead = 0;
    int numFramesRead = 0;
    // Try to read numBytes bytes from the file.
    while ((numBytesRead = 
      audioInputStream.read(audioBytes)) != -1) {
      // Calculate the number of frames actually read.
      numFramesRead = numBytesRead / bytesPerFrame;
      totalFramesRead += numFramesRead;
      // Here, do something useful with the audio data that's 
      // now in the audioBytes array...
    }
  } catch (Exception ex) { 
    // Handle the error...
  }
} catch (Exception e) {
  // Handle the error...
}
</pre></div>
<p>Let&#39;s take a look at what&#39;s happening in the above code sample. First, the outer try clause instantiates an <code>AudioInputStream</code> object through the call to the <code>AudioSystem.getAudioInputStream(File)</code> method. This method transparently performs all of the testing required to determine whether the specified file is actually a sound file of a type that is supported by the Java Sound API. If the file being inspected (<code>fileIn</code> in this example) is not a sound file, or is a sound file of some unsupported type, an <code>UnsupportedAudioFileException</code> exception is thrown. This behavior is convenient, in that the application programmer need not be bothered with testing file attributes, nor with adhering to any file-naming conventions. Instead, the <code>getAudioInputStream</code> method takes care of all the low-level parsing and verification that is required to validate the input file. <a name="114595"></a> The outer <code>try</code> clause then creates a byte array, <code>audioBytes</code>, of an arbitrary fixed length. We make sure that its length in bytes equals an integral number of frames, so that we won&#39;t end up reading only part of a frame or, even worse, only part of a sample. This byte array will serve as a buffer to temporarily hold a chunk of audio data as it&#39;s read from the stream. If we knew we would be reading nothing but very short sound files, we could make this array the same length as the data in the file, by deriving the length in bytes from the length in frames, as returned by <code>AudioInputStream&#39;s getFrameLength</code> method. (Actually, we&#39;d probably just use a <code>Clip</code> object instead.) But to avoid running out of memory in the general case, we instead read the file in chunks, one buffer at a time.</p>
<p><a name="114597"></a> The inner <code>try</code> clause contains a <code>while</code> loop, which is where we read the audio data from the <code>AudioInputStream</code> into the byte array. You should add code in this loop to handle the audio data in this array in whatever way is appropriate for your program&#39;s needs. If you&#39;re applying some kind of signal processing to the data, you&#39;ll probably need to query the <code>AudioInputStream&#39;s AudioFormat</code> further, to learn the number of bits per sample and so on.</p>
<p><a name="114599"></a> Note that the method <code>AudioInputStream.read(byte[])</code> returns the number of <em>bytes</em> read???not the number of samples or frames. This method returns -1 when there&#39;s no more data to read. Upon detecting this condition, we break from the <code>while</code> loop.</p>
<p><a name="114602"></a></p>
<h2>Writing Sound Files</h2>
<p><a name="114604"></a> The previous section described the basics of reading a sound file, using specific methods of the <code>AudioSystem</code> and <code>AudioInputStream</code> classes. This section describes how to write audio data out to a new file.</p>
<p><a name="114606"></a> The following <code>AudioSystem</code> method creates a disk file of a specified file type. The file will contain the audio data that&#39;s in the specified <code>AudioInputStream</code>:</p>
<div class="codeblock"><pre>
static int write(AudioInputStream in, 
  AudioFileFormat.Type fileType, File out)
</pre></div>
<p>Note that the second argument must be one of the file types supported by the system (for example, AU, AIFF, or WAV), otherwise the <code>write</code> method will throw an <code>IllegalArgumentException</code>. To avoid this, you can test whether or not a particular <code>AudioInputStream</code> may be written to a particular type of file, by invoking this <code>AudioSystem</code> method:</p>
<div class="codeblock"><pre>
static boolean isFileTypeSupported
  (AudioFileFormat.Type fileType, AudioInputStream stream)
</pre></div>
<p>which will return <code>true</code> only if the particular combination is supported.</p>
<p><a name="114618"></a> More generally, you can learn what types of file the system can write by invoking one of these <code>AudioSystem</code> methods:</p>
<div class="codeblock"><pre>
static AudioFileFormat.Type[] getAudioFileTypes() 
static AudioFileFormat.Type[] getAudioFileTypes(AudioInputStream stream) 
</pre></div>
<p>The first of these returns all the types of file that the system can write, and the second returns only those that the system can write from the given audio input stream.</p>
<p><a name="119705"></a> The following excerpt demonstrates one technique for creating an output file from an <code>AudioInputStream</code> using the <code>write</code> method mentioned above.</p>
<div class="codeblock"><pre>
File fileOut = new File(someNewPathName);
AudioFileFormat.Type fileType = fileFormat.getType();
if (AudioSystem.isFileTypeSupported(fileType, 
    audioInputStream)) {
  AudioSystem.write(audioInputStream, fileType, fileOut);
}
</pre></div>
<p>The first statement above, creates a new <code>File</code> object, <code>fileOut</code>, with a user- or program-specified pathname. The second statement gets a file type from a pre-existing <code>AudioFileFormat</code> object called <code>fileFormat</code>, which might have been obtained from another sound file, such as the one that was read in <a href="#114527">Reading Sound Files</a> above. (You could instead supply whatever supported file type you want, instead of getting the file type from elsewhere. For example, you might delete the second statement and replace the other two occurrences of <code>fileType</code> in the code above with <code>AudioFileFormat.Type.WAVE</code>.)</p>
<p><a name="114635"></a> The third statement tests whether a file of the designated type can be written from a desired <code>AudioInputStream</code>. Like the file format, this stream might have been derived from the sound file previously read. (If so, presumably you&#39;ve processed or altered its data in some way, because otherwise there are easier ways to simply copy a file.) Or perhaps the stream contains bytes that have been freshly captured from the microphone input.</p>
<p><a name="114637"></a> Finally, the stream, file type, and output file are passed to the <code>AudioSystem</code>.<code>write</code> method, to accomplish the goal of writing the file.</p>
<p><a name="114640"></a></p>
<h2>Converting File and Data Formats</h2>
<p><a name="114642"></a> Recall from 
<a class="TutorialLink" target="_top" href="sampled-overview.html#formatted">What is Formatted Audio Data?</a>, that the Java Sound API distinguishes between audio <em>file</em> formats and audio <em>data</em> formats. The two are more or less independent. Roughly speaking, the data format refers to the way in which the computer represents each raw data point (sample), while the file format refers to the organization of a sound file as stored on a disk. Each sound file format has a particular structure that defines, for example, the information stored in the file&#39;s header. In some cases, the file format also includes structures that contain some form of meta-data, in addition to the actual &quot;raw&quot; audio samples. The remainder of this page examines methods of the Java Sound API that enable a variety of file-format and data-format conversions.</p>
<p><a name="114644"></a></p>
<h2>Converting from One File Format to Another</h2>
<p><a name="114646"></a> This section covers the fundamentals of converting audio file types in the Java Sound API. Once again we pose a hypothetical program whose purpose, this time, is to read audio data from an arbitrary input file and write it into a file whose type is AIFF. Of course, the input file must be of a type that the system is capable of reading, and the output file must be of a type that the system is capable of writing. (In this example, we assume that the system is capable of writing AIFF files.) The example program doesn&#39;t do any data format conversion. If the input file&#39;s data format can&#39;t be represented as an AIFF file, the program simply notifies the user of that problem. On the other hand, if the input sound file is an already an AIFF file, the program notifies the user that there is no need to convert it.</p>
<p><a name="114648"></a> The following function implements the logic just described:</p>
<div class="codeblock"><pre>
public void ConvertFileToAIFF(String inputPath, 
  String outputPath) {
  AudioFileFormat inFileFormat;
  File inFile;
  File outFile;
  try {
    inFile = new File(inputPath);
    outFile = new File(outputPath);     
  } catch (NullPointerException ex) {
    System.out.println("Error: one of the 
      ConvertFileToAIFF" +" parameters is null!");
    return;
  }
  try {
    // query file type
    inFileFormat = AudioSystem.getAudioFileFormat(inFile);
    if (inFileFormat.getType() != AudioFileFormat.Type.AIFF) 
    {
      // inFile is not AIFF, so let's try to convert it.
      AudioInputStream inFileAIS = 
        AudioSystem.getAudioInputStream(inFile);
      inFileAIS.reset(); // rewind
      if (AudioSystem.isFileTypeSupported(
             AudioFileFormat.Type.AIFF, inFileAIS)) {
         // inFileAIS can be converted to AIFF. 
         // so write the AudioInputStream to the
         // output file.
         AudioSystem.write(inFileAIS,
           AudioFileFormat.Type.AIFF, outFile);
         System.out.println("Successfully made AIFF file, "
           + outFile.getPath() + ", from "
           + inFileFormat.getType() + " file, " +
           inFile.getPath() + ".");
         inFileAIS.close();
         return; // All done now
       } else
         System.out.println("Warning: AIFF conversion of " 
           + inFile.getPath()
           + " is not currently supported by AudioSystem.");
    } else
      System.out.println("Input file " + inFile.getPath() +
          " is AIFF." + " Conversion is unnecessary.");
  } catch (UnsupportedAudioFileException e) {
    System.out.println("Error: " + inFile.getPath()
        + " is not a supported audio file type!");
    return;
  } catch (IOException e) {
    System.out.println("Error: failure attempting to read " 
      + inFile.getPath() + "!");
    return;
  }
}
</pre></div>
<p><a name="114706"></a> As mentioned, the purpose of this example function, <code>ConvertFileToAIFF</code>, is to query an input file to determine whether it&#39;s an AIFF sound file, and if it isn&#39;t, to try to convert it to one, producing a new copy whose pathname is specified by the second argument. (As an exercise, you might try making this function more general, so that instead of always converting to AIFF, the function converts to the file type specified by a new function argument.) Note that the audio data format of the copy???that is, the new file-mimics the audio data format of original input file.</p>
<p><a name="114708"></a> Most of this function is self-explanatory and is not specific to the Java Sound API. There are, however, a few Java Sound API methods used by the routine that are crucial for sound file-type conversions. These method invocations are all found in the second <code>try</code> clause, above, and include the following:</p>
<ul>
<li><a name="114710"></a><code>AudioSystem.getAudioFileFormat</code>: used here to determine whether the input file is already an AIFF type. If so, the function quickly returns; otherwise the conversion attempt proceeds.</li>
<li><a name="114712"></a><code>AudioSystem.isFileTypeSupported</code>: Indicates whether the system can write a file of the specified type that contains audio data from the specified <code>AudioInputStream.</code> In our example, this method returns <code>true</code> if the specified audio input file can be converted to AIFF audio file format. If <code>AudioFileFormat.Type.AIFF</code> isn&#39;t supported, <code>ConvertFileToAIFF</code> issues a warning that the input file can&#39;t be converted, then returns.</li>
<li><a name="114714"></a><code>AudioSystem.write</code>: used here to write the audio data from the AudioInputStream <code>inFileAIS</code> to the output file <code>outFile</code>.</li>
</ul>
<p><a name="114716"></a> The second of these methods, <code>isFileTypeSupported</code>, helps to determine, in advance of the write, whether a particular input sound file can be converted to a particular output sound file type. In the next section we will see how, with a few modifications to this <code>ConvertFileToAIFF</code> sample routine, we can convert the audio data format, as well as the sound file type.</p>
<p><a name="114718"></a></p>
<h2>Converting Audio between Different Data Formats</h2>
<p><a name="114720"></a> The previous section showed how to use the Java Sound API to convert a file from one <em>file</em> format (that is, one type of sound file) to another. This section explores some of the methods that enable audio <em>data</em> format conversions.</p>
<p><a name="114722"></a> In the previous section, we read data from a file of an arbitrary type, and saved it in an AIFF file. Note that although we changed the type of file used to store the data, we didn&#39;t change the format of the audio data itself. (Most common audio file types, including AIFF, can contain audio data of various formats.) So if the original file contained CD-quality audio data (16-bit sample size, 44.1-kHz sample rate, and two channels), so would our output AIFF file.</p>
<p><a name="114724"></a> Now suppose that we want to specify the <em>data</em> format of the output file, as well as the file type. For example, perhaps we are saving many long files for use on the Internet, and are concerned about the amount of disk space and download time required by our files. We might choose to create smaller AIFF files that contain lower-resolution data-for example, data that has an 8-bit sample size, an 8-kHz sample rate, and a single channel.</p>
<p><a name="114726"></a> Without going into as much coding detail as before, let&#39;s explore some of the methods used for data format conversion, and consider the modifications that we would need to make to the <code>ConvertFileToAIFF</code> function to accomplish the new goal.</p>
<p><a name="118599"></a> The principal method for audio data conversion is, once again, found in the <code>AudioSystem</code> class. This method is a variant of <code>getAudioInputStream</code>:</p>
<div class="codeblock"><pre>
AudioInputStream getAudioInputStream(AudioFormat
    format, AudioInputStream stream)
</pre></div>
<p>This function returns an <code>AudioInputStream</code> that is the result of converting the <code>AudioInputStream</code>, <code>stream</code>, using the indicated <code>AudioFormat</code>, <code>format</code>. If the conversion isn&#39;t supported by <code>AudioSystem</code>, this function throws an <code>IllegalArgumentException</code>.</p>
<p><a name="114734"></a> To avoid that, we can first check whether the system can perform the required conversion by invoking this <code>AudioSystem</code> method:</p>
<div class="codeblock"><pre>
boolean isConversionSupported(AudioFormat targetFormat,
    AudioFormat sourceFormat)
</pre></div>
<p>In this case, we&#39;d pass <code>stream.getFormat()</code> as the second argument.</p>
<p><a name="119726"></a> To create a specific <code>AudioFormat</code> object, we use one of the two <code>AudioFormat</code> constructors shown below, either:</p>
<div class="codeblock"><pre>
AudioFormat(float sampleRate, int sampleSizeInBits,
    int channels, boolean signed, boolean bigEndian)
</pre></div>
<p>which constructs an <code>AudioFormat</code> with a linear PCM encoding and the given parameters, or:</p>
<div class="codeblock"><pre>
AudioFormat(AudioFormat.Encoding encoding, 
    float sampleRate, int sampleSizeInBits, int channels,
    int frameSize, float frameRate, boolean bigEndian) 
</pre></div>
<p>which also constructs an <code>AudioFormat</code>, but lets you specify the encoding, frame size, and frame rate, in addition to the other parameters.</p>
<p><a name="114751"></a> Now, armed with the methods above, let&#39;s see how we might extend our <code>ConvertFileToAIFF</code> function to perform the desired &quot;low-res&quot; audio data format conversion. First, we would construct an <code>AudioFormat</code> object describing the desired output audio data format. The following statement would suffice and could be inserted near the top of the function:</p>
<div class="codeblock"><pre>
AudioFormat outDataFormat = new AudioFormat((float) 8000.0,
(int) 8, (int) 1, true, false);
</pre></div>
<p>Since the <code>AudioFormat</code> constructor above is describing a format with 8-bit samples, the last parameter to the constructor, which specifies whether the samples are big or little endian, is irrelevant. (Big versus little endian is only an issue if the sample size is greater than a single byte.)</p>
<p><a name="114758"></a> The following example shows how we would use this new <code>AudioFormat</code> to convert the <code>AudioInputStream</code>, <code>inFileAIS</code>, that we created from the input file:</p>
<div class="codeblock"><pre>
AudioInputStream lowResAIS;         
  if (AudioSystem.isConversionSupported(outDataFormat,   
    inFileAIS.getFormat())) {
    lowResAIS = AudioSystem.getAudioInputStream
      (outDataFormat, inFileAIS);
  }
</pre></div>
<p>It wouldn&#39;t matter too much where we inserted this code, as long as it was after the construction of <code>inFileAIS</code>. Without the <code>isConversionSupported</code> test, the call would fail and throw an <code>IllegalArgumentException</code> if the particular conversion being requested was unsupported. (In this case, control would transfer to the appropriate <code>catch</code> clause in our function.)</p>
<p><a name="114769"></a> So by this point in the process, we would have produced a new <code>AudioInputStream</code>, resulting from the conversion of the original input file (in its <code>AudioInputStream</code> form) to the desired low-resolution audio data format as defined by <code>outDataFormat</code>.</p>
<p><a name="114771"></a> The final step to produce the desired low-resolution, AIFF sound file would be to replace the <code>AudioInputStream</code> parameter in the call to <code>AudioSystem.write</code> (that is, the first parameter) with our converted stream, <code>lowResAIS</code>, as follows:</p>
<div class="codeblock"><pre>
AudioSystem.write(lowResAIS, AudioFileFormat.Type.AIFF, 
  outFile);
</pre></div>
<p>These few modifications to our earlier function produce something that converts both the audio data and the file format of any specified input file, assuming of course that the system supports the conversion. <a name="114777"></a></p>
<h2>Learning What Conversions Are Available</h2>
<p><a name="114779"></a> Several <code>AudioSystem</code> methods test their parameters to determine whether the system supports a particular data format conversion or file-writing operation. (Typically, each method is paired with another that performs the data conversion or writes the file.) One of these query methods, <code>AudioSystem.isFileTypeSupported</code>, was used in our example function, <code>ConvertFileToAIFF</code>, to determine whether the system was capable of writing the audio data to an AIFF file. A related <code>AudioSystem</code> method, <code>getAudioFileTypes(AudioInputStream)</code>, returns the complete list of supported file types for the given stream, as an array of <code>AudioFileFormat.Type</code> instances. The method: BEGINCODE boolean isConversionSupported(AudioFormat.Encoding encoding,<br />
AudioFormat format) </pre></div> is used to determine whether an audio input stream of the specified encoding can be obtained from an audio input stream that has the specified audio format. Similarly, the method:</p>
<div class="codeblock"><pre>
boolean isConversionSupported(AudioFormat newFormat,
                              AudioFormat oldFormat) 
</pre></div>
<p><a name="114790"></a> tells us whether an <code>AudioInputStream</code> with the specified audio format, <code>newFormat</code>, can be obtained through the conversion of an <code>AudioInputStream</code> that has the audio format <code>oldFormat</code>. (This method was invoked in the previous section&#39;s code excerpt that created a low-resolution audio input stream, <code>lowResAIS</code>.)</p>
<p><a name="114792"></a> These format-related queries help prevent errors when attempting to perform format conversions with the Java Sound API.</p>


        </div>
        <div class="NavBit">
            <a target="_top" href="controls.html">&laquo; Previous</a>
            &bull;
            <a target="_top" href="./TOC.html">Trail</a>
            &bull;
            <a target="_top" href="overview-MIDI.html">Next &raquo;</a>
        </div>
    </div>
    
<hr class="clearfloat"/>

<div id="Footer">
<table width="100%" border="0" cellspacing="0" cellpadding="5" summary="">
<tr>
    <td>
         <p class="footertext"><a name="license_info">Your use of this</a> page and all the material on pages under &quot;The Java Tutorials&quot; banner 
         is subject to these <a href="../information/cpyr.html">legal notices</a>.
         </p>
         <p class="footertext">Copyright &copy; 1995, 2015 Oracle and/or its affiliates. All rights reserved.</p>
    </td>
    
    <td align="right">
        <p class="footertext">Problems with the examples? Try <a target="_blank"
        href="../information/run-examples.html">Compiling and Running
        the Examples: FAQs</a>.
        </p>
        <p class="footertext">
        Complaints? Compliments? Suggestions? <a target="_blank"
            href="https://docs.oracle.com/javase/feedback.html">Give
        us your feedback</a>.       
        </p>
    </td>
    
</tr>
</table>
  
</div>
    
    <div class="PrintHeaders">
        <b>Previous page:</b> Processing Audio with Controls
        <br /><b>Next page:</b> Overview of the MIDI Package
    </div>
</body>
</html> 
